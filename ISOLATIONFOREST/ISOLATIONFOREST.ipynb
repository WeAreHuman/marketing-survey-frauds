{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "vjffpa3kuxm5l7jmhcvb",
   "authorId": "6456646925662",
   "authorName": "SURPATIL",
   "authorEmail": "secompconfessions@gmail.com",
   "sessionId": "f0456f92-17c7-4d00-b3ce-3b2936394f3f",
   "lastEditTime": 1765235148761
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "5b0854e6-2810-4784-af71-9dcc2996614a",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "session = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Core imports\nimport pandas as pd\nimport numpy as np\n\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\n\n# ML imports\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.decomposition import PCA\n\nimport matplotlib.pyplot as plt\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9cbcfca9-c25f-4338-8ce2-1373e231b2b0",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# 1) Load table from Snowflake\nsf_df = session.table(\"PUBLIC.PANELIST_ALL_FEATURES_ENC\")\n\n# 2) Convert to pandas for sklearn\npdf = sf_df.to_pandas()\n\n# 3) Identify columns\nid_col = \"PANELIST_ID\"\n\nall_cols = list(pdf.columns)\nnumeric_cols = [c for c in all_cols if c != id_col]\n\nprint(\"ID column:\", id_col)\nprint(\"Number of numeric feature columns:\", len(numeric_cols))\nprint(\"Sample feature columns:\", numeric_cols[:10])\nprint(\"Number of rows:\", len(pdf))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57e4de4d-5a69-4ee2-a698-ddebe8b19d58",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "# Separate features (X) and ID\nX_raw = pdf[numeric_cols].values\n\n# 1) Impute missing values\nimputer = SimpleImputer(strategy=\"mean\")\nX_imputed = imputer.fit_transform(X_raw)\n\n# 2) Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_imputed)\n\nprint(\"Shape of X_scaled:\", X_scaled.shape)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12111fe0-ec47-4851-87c7-4b2e23aa971b",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# Isolation Forest model\niso = IsolationForest(\n    n_estimators=200,     # number of trees\n    contamination=0.02,  # assume ~2% anomalies (tune this!)\n    random_state=42,\n    n_jobs=-1            # use all cores if available\n)\n\niso.fit(X_scaled)\n\n# Predict:\n# -1 = anomaly, 1 = normal\nlabels = iso.predict(X_scaled)\nscores = -iso.decision_function(X_scaled)  # higher score = more anomalous\n\n# Attach to dataframe\npdf[\"ANOMALY_LABEL\"] = labels\npdf[\"ANOMALY_SCORE\"] = scores\n\n# For convenience, make a 0/1 flag\n# 1 = anomaly, 0 = normal\npdf[\"ANOMALY_FLAG\"] = (pdf[\"ANOMALY_LABEL\"] == -1).astype(int)\n\n# Quick summary\nprint(\"Total rows:\", len(pdf))\nprint(\"Anomaly count:\", pdf[\"ANOMALY_FLAG\"].sum())\nprint(\"Anomaly %:\", pdf[\"ANOMALY_FLAG\"].mean() * 100)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7de3cc3-823b-44d3-aade-efb5132850e0",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Collect feature importances from all trees\ntree_importances = np.array([tree.feature_importances_ for tree in iso.estimators_])\n\n# Average importance across all trees\nfeature_importance = tree_importances.mean(axis=0)\n\n# Create a sorted Series\nfeat_imp = pd.Series(feature_importance, index=numeric_cols).sort_values(ascending=False)\n\nprint(\"Top 20 most important features:\")\ndisplay(feat_imp.head(20))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bebb1a7-83da-4202-b6b0-b484366e2f1f",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "# Optional: sample for plotting\nmax_points = 5000\nn = len(pdf)\n\nif n > max_points:\n    sample_idx = np.random.choice(n, size=max_points, replace=False)\nelse:\n    sample_idx = np.arange(n)\n\nX_sample = X_scaled[sample_idx]\nanom_sample = pdf[\"ANOMALY_FLAG\"].values[sample_idx]\n\n# 2D PCA\npca_vis = PCA(n_components=2, random_state=42)\nX_pca_2d = pca_vis.fit_transform(X_sample)\n\nplt.figure(figsize=(8, 6))\nplt.scatter(\n    X_pca_2d[:, 0],\n    X_pca_2d[:, 1],\n    c=anom_sample,\n    s=8,\n    alpha=0.7\n)\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"Isolation Forest Anomalies (1 = red-ish, 0 = blue-ish)\")\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a139172e-864e-4a6e-88d6-c6a091771b71",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "result_cols = [id_col, \"ANOMALY_FLAG\", \"ANOMALY_SCORE\"]\n\nresult_pdf = pdf[result_cols].copy()\n\nresult = session.write_pandas(\n    result_pdf,\n    \"PANELIST_ISOFOREST_SCORED\",\n    auto_create_table=True,\n    overwrite=True\n)\n\nprint(\"write_pandas result:\", result)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a52ad22-bb36-4502-a243-eecef4a28cf2",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "SELECT ANOMALY_FLAG, COUNT(*)\nFROM PUBLIC.PANELIST_ISOFOREST_SCORED\nGROUP BY ANOMALY_FLAG\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb1eee66-0a29-4fea-bf07-ee1b269004fc",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "# Split anomalies and normals\nanom = pdf[pdf[\"ANOMALY_FLAG\"] == 1].copy()\nnorm = pdf[pdf[\"ANOMALY_FLAG\"] == 0].copy()\n\nprint(\"Anomalies:\", len(anom))\nprint(\"Normals:\", len(norm))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10059958-70db-498a-bbea-60270a1f5781",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "# Select features of the first anomaly\nanomaly_row_raw = anom[numeric_cols].iloc[0].values.reshape(1, -1)\n\n# Scale it (SHAP requires scaled values)\nanomaly_row_scaled = scaler.transform(anomaly_row_raw)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7ce8ceb-bf1e-4914-bf2c-e82d5aff80fc",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "import shap\n\n# Create SHAP explainer for Isolation Forest\nexplainer = shap.TreeExplainer(iso)\n\n# Compute SHAP values for the single anomaly\nshap_values_single = explainer.shap_values(anomaly_row_scaled)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4f90602-40a7-4651-9057-a32f645ae12e",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "anomaly_row = anom.iloc[0][numeric_cols].values.reshape(1, -1)\nshap_values_single = explainer.shap_values(scaler.transform(anomaly_row))\n\nshap.force_plot(\n    explainer.expected_value,\n    shap_values_single,\n    anomaly_row,\n    feature_names=numeric_cols\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0427cb2c-fe9a-482b-a34d-a77c2388cb11",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "shap.summary_plot(\n    shap_values_single,\n    anomaly_row_scaled,\n    feature_names=numeric_cols\n)\n",
   "execution_count": null
  }
 ]
}